"""
Gradioå¯è§†åŒ–ç•Œé¢ - è®­ç»ƒç›‘æ§ã€å‚æ•°è°ƒæ•´å’Œæ¨ç†æµ‹è¯•
"""
import gradio as gr
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import json
import os
import threading
import time
from datetime import datetime

from config import Config
from data_processor import DataProcessor
from trainer import Trainer
from inference import load_all_models
from models import ModelFactory

class GradioApp:
    """Gradioåº”ç”¨ç¨‹åºç±»"""
    
    def __init__(self):
        self.config = Config()
        self.data_processor = None
        self.trainer = None
        self.evaluator = None
        self.processed_groups = None
        self.training_thread = None
        self.training_status = {"is_training": False, "progress": 0, "current_group": "", "current_model": ""}
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.initialize_components()
    
    def initialize_components(self):
        """åˆå§‹åŒ–ç»„ä»¶"""
        try:
            self.data_processor = DataProcessor(self.config)
            self.trainer = Trainer(self.config)
            self.evaluator = load_all_models()
            print("ç»„ä»¶åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def load_data(self, x_file, y_file):
        """åŠ è½½æ•°æ®"""
        try:
            if x_file is None or y_file is None:
                # ä½¿ç”¨ç¤ºä¾‹æ•°æ®
                X, y = self.data_processor._generate_sample_data()
                message = "ä½¿ç”¨ç”Ÿæˆçš„ç¤ºä¾‹æ•°æ®"
            else:
                # ç›´æ¥ä½¿ç”¨ä¸Šä¼ æ–‡ä»¶çš„è·¯å¾„
                X, y = self.data_processor.load_data(x_file.name, y_file.name)
                message = f"æˆåŠŸåŠ è½½æ•°æ®: X={X.shape}, y={y.shape}"
            
            # å¤„ç†æ•°æ®
            self.processed_groups = self.data_processor.process_all_groups(X, y)
            
            # ç”Ÿæˆæ•°æ®ç»Ÿè®¡ä¿¡æ¯
            stats = self.generate_data_stats()
            
            return message, stats
            
        except Exception as e:
            return f"æ•°æ®åŠ è½½å¤±è´¥: {e}", ""
    
    def generate_data_stats(self):
        """ç”Ÿæˆæ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        if not self.processed_groups:
            return "æ— æ•°æ®"
        
        stats = "æ•°æ®ç»Ÿè®¡ä¿¡æ¯:\n"
        stats += "=" * 30 + "\n"
        
        for group_name, group_data in self.processed_groups.items():
            train_size = len(group_data['data_splits']['train'][0])
            val_size = len(group_data['data_splits']['val'][0])
            test_size = len(group_data['data_splits']['test'][0])
            
            stats += f"{group_name}:\n"
            stats += f"  è®­ç»ƒé›†: {train_size} æ ·æœ¬\n"
            stats += f"  éªŒè¯é›†: {val_size} æ ·æœ¬\n"
            stats += f"  æµ‹è¯•é›†: {test_size} æ ·æœ¬\n"
            stats += f"  æ€»è®¡: {train_size + val_size + test_size} æ ·æœ¬\n\n"
        
        return stats
    
    def update_config(self, learning_rate, batch_size, epochs, hidden_dims, dropout_rate):
        """æ›´æ–°é…ç½®å‚æ•°"""
        try:
            # éªŒè¯å‚æ•°èŒƒå›´
            if learning_rate <= 0 or learning_rate > 1:
                return "å­¦ä¹ ç‡å¿…é¡»åœ¨ (0, 1] èŒƒå›´å†…"
            if batch_size <= 0 or batch_size > 1024:
                return "æ‰¹æ¬¡å¤§å°å¿…é¡»åœ¨ (0, 1024] èŒƒå›´å†…"
            if epochs <= 0 or epochs > 1000:
                return "è®­ç»ƒè½®æ•°å¿…é¡»åœ¨ (0, 1000] èŒƒå›´å†…"
            if dropout_rate < 0 or dropout_rate >= 1:
                return "Dropoutç‡å¿…é¡»åœ¨ [0, 1) èŒƒå›´å†…"
            
            self.config.LEARNING_RATE = learning_rate
            self.config.BATCH_SIZE = int(batch_size)
            self.config.EPOCHS = int(epochs)
            self.config.DROPOUT_RATE = dropout_rate
            
            # è§£æéšè—å±‚ç»´åº¦
            if hidden_dims:
                try:
                    dims = [int(x.strip()) for x in hidden_dims.split(',')]
                    if any(d <= 0 for d in dims):
                        return "éšè—å±‚ç»´åº¦å¿…é¡»ä¸ºæ­£æ•´æ•°"
                    self.config.HIDDEN_DIMS = dims
                except ValueError:
                    return "éšè—å±‚ç»´åº¦æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨é€—å·åˆ†éš”çš„æ•´æ•°"
            
            return "é…ç½®æ›´æ–°æˆåŠŸ"
        except Exception as e:
            return f"é…ç½®æ›´æ–°å¤±è´¥: {e}"
    
    def start_training(self, selected_groups, selected_models, progress=gr.Progress()):
        """å¼€å§‹è®­ç»ƒ"""
        if not self.processed_groups:
            return "è¯·å…ˆåŠ è½½æ•°æ®"
        
        if self.training_status["is_training"]:
            return "è®­ç»ƒæ­£åœ¨è¿›è¡Œä¸­ï¼Œè¯·ç­‰å¾…å®Œæˆ"
        
        try:
            # è¿‡æ»¤é€‰ä¸­çš„ç»„å’Œæ¨¡å‹
            groups_to_train = {k: v for k, v in self.processed_groups.items() if k in selected_groups}
            
            if not groups_to_train:
                return "è¯·é€‰æ‹©è¦è®­ç»ƒçš„æ•°æ®ç»„"
            
            if not selected_models:
                return "è¯·é€‰æ‹©è¦è®­ç»ƒçš„æ¨¡å‹ç±»å‹"
            
            # å¯åŠ¨è®­ç»ƒçº¿ç¨‹
            self.training_thread = threading.Thread(
                target=self._train_models,
                args=(groups_to_train, selected_models, progress)
            )
            self.training_thread.start()
            
            return "è®­ç»ƒå·²å¼€å§‹ï¼Œè¯·æŸ¥çœ‹è®­ç»ƒçŠ¶æ€"
            
        except Exception as e:
            return f"å¯åŠ¨è®­ç»ƒå¤±è´¥: {e}"
    
    def _train_models(self, groups_to_train, selected_models, progress):
        """è®­ç»ƒæ¨¡å‹ï¼ˆåœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œï¼‰"""
        self.training_status["is_training"] = True
        
        try:
            total_tasks = len(groups_to_train) * len(selected_models)
            current_task = 0
            
            for group_name, group_data in groups_to_train.items():
                for model_type in selected_models:
                    self.training_status["current_group"] = group_name
                    self.training_status["current_model"] = model_type
                    
                    # è®­ç»ƒæ¨¡å‹
                    self.trainer.train_group(group_name, group_data, model_type)
                    
                    current_task += 1
                    self.training_status["progress"] = (current_task / total_tasks) * 100
                    
                    if progress:
                        progress((current_task / total_tasks), f"è®­ç»ƒ {group_name} - {model_type}")
            
            self.training_status["is_training"] = False
            self.training_status["progress"] = 100
            
        except Exception as e:
            print(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            self.training_status["is_training"] = False
    
    def get_training_status(self):
        """è·å–è®­ç»ƒçŠ¶æ€"""
        if self.training_status["is_training"]:
            return f"è®­ç»ƒä¸­... {self.training_status['progress']:.1f}%\n" \
                   f"å½“å‰: {self.training_status['current_group']} - {self.training_status['current_model']}"
        else:
            if self.training_status["progress"] == 100:
                return "è®­ç»ƒå®Œæˆ"
            else:
                return "æœªå¼€å§‹è®­ç»ƒ"
    
    def load_training_results(self):
        """åŠ è½½è®­ç»ƒç»“æœ"""
        try:
            results_path = os.path.join(self.config.LOG_DIR, "training_results.json")
            
            if not os.path.exists(results_path):
                return "æœªæ‰¾åˆ°è®­ç»ƒç»“æœæ–‡ä»¶"
            
            with open(results_path, 'r', encoding='utf-8') as f:
                results = json.load(f)
            
            # ç”Ÿæˆç»“æœæ‘˜è¦
            summary = "è®­ç»ƒç»“æœæ‘˜è¦:\n"
            summary += "=" * 30 + "\n"
            
            for group_name, group_results in results.items():
                summary += f"{group_name}:\n"
                
                for model_type, history in group_results.items():
                    if 'final_test' in history:
                        test_results = history['final_test']
                        summary += f"  {model_type}:\n"
                        summary += f"    MSE: {test_results['mse']:.6f}\n"
                        summary += f"    MAE: {test_results['mae']:.6f}\n"
                        summary += f"    RÂ²: {test_results['r2']:.4f}\n\n"
                
                summary += "\n"
            
            return summary
            
        except Exception as e:
            return f"åŠ è½½è®­ç»ƒç»“æœå¤±è´¥: {e}"
    
    def create_training_plots(self, selected_group):
        """åˆ›å»ºè®­ç»ƒæ›²çº¿å›¾"""
        try:
            results_path = os.path.join(self.config.LOG_DIR, "training_results.json")
            
            if not os.path.exists(results_path):
                return None
            
            with open(results_path, 'r', encoding='utf-8') as f:
                results = json.load(f)
            
            if selected_group not in results:
                return None
            
            group_results = results[selected_group]
            
            # åˆ›å»ºå­å›¾
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=('è®­ç»ƒ/éªŒè¯æŸå¤±', 'MSE', 'RÂ²åˆ†æ•°', 'å­¦ä¹ ç‡'),
                specs=[[{"secondary_y": False}, {"secondary_y": False}],
                       [{"secondary_y": False}, {"secondary_y": True}]]
            )
            
            colors = ['blue', 'red', 'green', 'orange', 'purple']
            
            for i, (model_type, history) in enumerate(group_results.items()):
                color = colors[i % len(colors)]
                
                epochs = list(range(1, len(history['train_loss']) + 1))
                
                # è®­ç»ƒ/éªŒè¯æŸå¤±
                fig.add_trace(
                    go.Scatter(x=epochs, y=history['train_loss'], 
                              name=f'{model_type} - è®­ç»ƒæŸå¤±', 
                              line=dict(color=color, dash='solid')),
                    row=1, col=1
                )
                fig.add_trace(
                    go.Scatter(x=epochs, y=history['val_loss'], 
                              name=f'{model_type} - éªŒè¯æŸå¤±', 
                              line=dict(color=color, dash='dash')),
                    row=1, col=1
                )
                
                # MSE
                fig.add_trace(
                    go.Scatter(x=epochs, y=history['val_mse'], 
                              name=f'{model_type} - MSE', 
                              line=dict(color=color)),
                    row=1, col=2
                )
                
                # RÂ²
                fig.add_trace(
                    go.Scatter(x=epochs, y=history['val_r2'], 
                              name=f'{model_type} - RÂ²', 
                              line=dict(color=color)),
                    row=2, col=1
                )
                
                # å­¦ä¹ ç‡
                fig.add_trace(
                    go.Scatter(x=epochs, y=history['learning_rate'], 
                              name=f'{model_type} - å­¦ä¹ ç‡', 
                              line=dict(color=color)),
                    row=2, col=2
                )
            
            fig.update_layout(height=800, title_text=f"{selected_group} è®­ç»ƒæ›²çº¿")
            fig.update_yaxes(type="log", row=2, col=2)  # å­¦ä¹ ç‡ä½¿ç”¨å¯¹æ•°åæ ‡
            
            return fig
            
        except Exception as e:
            print(f"åˆ›å»ºè®­ç»ƒå›¾è¡¨å¤±è´¥: {e}")
            return None
    
    def predict_single(self, input_values, selected_group, selected_model):
        """å•ä¸ªé¢„æµ‹"""
        try:
            if not self.evaluator or not self.evaluator.inference.models:
                return "è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹"
            
            # è§£æè¾“å…¥å€¼
            if isinstance(input_values, str):
                values = [float(x.strip()) for x in input_values.split(',')]
            else:
                values = input_values
            
            if len(values) != self.config.INPUT_DIM:
                return f"è¾“å…¥ç»´åº¦é”™è¯¯ï¼ŒæœŸæœ› {self.config.INPUT_DIM} ä¸ªå€¼"
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            X = np.array(values).reshape(1, -1)
            
            # é¢„æµ‹
            model_key = f"{selected_group}_{selected_model}"
            
            if model_key not in self.evaluator.inference.models:
                return f"æ¨¡å‹ {model_key} æœªåŠ è½½"
            
            prediction = self.evaluator.inference.predict(model_key, X, selected_group)
            
            # æ ¼å¼åŒ–è¾“å‡º
            result = f"é¢„æµ‹ç»“æœ ({selected_group} - {selected_model}):\n"
            result += "=" * 40 + "\n"
            
            for i, value in enumerate(prediction[0]):
                result += f"è¾“å‡º {i+1}: {value:.6f}\n"
            
            return result
            
        except Exception as e:
            return f"é¢„æµ‹å¤±è´¥: {e}"
    
    def batch_predict(self, csv_file, selected_group, selected_models):
        """æ‰¹é‡é¢„æµ‹"""
        try:
            if not self.evaluator or not self.evaluator.inference.models:
                return "è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹", None
            
            if csv_file is None:
                return "è¯·ä¸Šä¼ CSVæ–‡ä»¶", None
            
            # è¯»å–CSVæ–‡ä»¶
            df = pd.read_csv(csv_file.name)
            X = df.values
            
            if X.shape[1] != self.config.INPUT_DIM:
                return f"è¾“å…¥ç»´åº¦é”™è¯¯ï¼ŒæœŸæœ› {self.config.INPUT_DIM} ä¸ªç‰¹å¾", None
            
            # æ‰¹é‡é¢„æµ‹
            predictions = self.evaluator.inference.batch_predict(X, selected_group, selected_models)
            
            if not predictions:
                return "æ²¡æœ‰å¯ç”¨çš„é¢„æµ‹ç»“æœ", None
            
            # åˆ›å»ºç»“æœDataFrame
            result_df = df.copy()
            
            for model_type, pred in predictions.items():
                for i in range(pred.shape[1]):
                    result_df[f'{model_type}_output_{i+1}'] = pred[:, i]
            
            # ä¿å­˜ç»“æœ
            output_path = f"batch_predictions_{selected_group}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            result_df.to_csv(output_path, index=False)
            
            return f"æ‰¹é‡é¢„æµ‹å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ° {output_path}", result_df
            
        except Exception as e:
            return f"æ‰¹é‡é¢„æµ‹å¤±è´¥: {e}", None
    
    def create_interface(self):
        """åˆ›å»ºGradioç•Œé¢"""
        with gr.Blocks(title="æ·±åº¦å­¦ä¹ å›å½’é¢„æµ‹ç³»ç»Ÿ", theme=gr.themes.Soft()) as app:
            gr.Markdown("# ğŸ§  æ·±åº¦å­¦ä¹ å›å½’é¢„æµ‹ç³»ç»Ÿ")
            gr.Markdown("å¤šè¾“å…¥å¤šè¾“å‡ºå›å½’é¢„æµ‹ï¼Œæ”¯æŒMLPã€ResNetã€Transformerç­‰å¤šç§æ¨¡å‹æ¶æ„")
            
            with gr.Tabs():
                # æ•°æ®åŠ è½½æ ‡ç­¾é¡µ
                with gr.TabItem("ğŸ“Š æ•°æ®åŠ è½½"):
                    gr.Markdown("## æ•°æ®åŠ è½½å’Œé¢„å¤„ç†")
                    
                    with gr.Row():
                        x_file = gr.File(label="è¾“å…¥æ•°æ®æ–‡ä»¶ (x_input.csv)", file_types=[".csv"])
                        y_file = gr.File(label="è¾“å‡ºæ•°æ®æ–‡ä»¶ (y_output.csv)", file_types=[".csv"])
                    
                    load_btn = gr.Button("åŠ è½½æ•°æ®", variant="primary")
                    load_status = gr.Textbox(label="åŠ è½½çŠ¶æ€", lines=2)
                    data_stats = gr.Textbox(label="æ•°æ®ç»Ÿè®¡", lines=10)
                    
                    load_btn.click(
                        self.load_data,
                        inputs=[x_file, y_file],
                        outputs=[load_status, data_stats]
                    )
                
                # è®­ç»ƒé…ç½®æ ‡ç­¾é¡µ
                with gr.TabItem("âš™ï¸ è®­ç»ƒé…ç½®"):
                    gr.Markdown("## æ¨¡å‹è®­ç»ƒé…ç½®")
                    
                    with gr.Row():
                        with gr.Column():
                            learning_rate = gr.Number(label="å­¦ä¹ ç‡", value=self.config.LEARNING_RATE)
                            batch_size = gr.Number(label="æ‰¹æ¬¡å¤§å°", value=self.config.BATCH_SIZE, precision=0)
                            epochs = gr.Number(label="è®­ç»ƒè½®æ•°", value=self.config.EPOCHS, precision=0)
                        
                        with gr.Column():
                            hidden_dims = gr.Textbox(
                                label="éšè—å±‚ç»´åº¦ (é€—å·åˆ†éš”)", 
                                value=",".join(map(str, self.config.HIDDEN_DIMS))
                            )
                            dropout_rate = gr.Number(label="Dropoutç‡", value=self.config.DROPOUT_RATE)
                    
                    config_btn = gr.Button("æ›´æ–°é…ç½®", variant="secondary")
                    config_status = gr.Textbox(label="é…ç½®çŠ¶æ€")
                    
                    config_btn.click(
                        self.update_config,
                        inputs=[learning_rate, batch_size, epochs, hidden_dims, dropout_rate],
                        outputs=[config_status]
                    )
                
                # æ¨¡å‹è®­ç»ƒæ ‡ç­¾é¡µ
                with gr.TabItem("ğŸš€ æ¨¡å‹è®­ç»ƒ"):
                    gr.Markdown("## æ¨¡å‹è®­ç»ƒ")
                    
                    with gr.Row():
                        with gr.Column():
                            selected_groups = gr.CheckboxGroup(
                                choices=["group_1", "group_2", "group_3", "group_4", "group_5"],
                                label="é€‰æ‹©æ•°æ®ç»„",
                                value=["group_1"]
                            )
                            
                            selected_models = gr.CheckboxGroup(
                                choices=["mlp", "resnet", "transformer"],
                                label="é€‰æ‹©æ¨¡å‹ç±»å‹",
                                value=["mlp"]
                            )
                        
                        with gr.Column():
                            train_btn = gr.Button("å¼€å§‹è®­ç»ƒ", variant="primary")
                            training_status = gr.Textbox(label="è®­ç»ƒçŠ¶æ€", lines=3)
                            
                            # ä½¿ç”¨å®šæ—¶å™¨å®šæœŸæ›´æ–°è®­ç»ƒçŠ¶æ€
                            def update_status():
                                return self.get_training_status()
                            
                            # æ³¨æ„ï¼šåœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨åˆ·æ–°é¡µé¢æ¥æŸ¥çœ‹è®­ç»ƒçŠ¶æ€
                            # æˆ–è€…ä½¿ç”¨å…¶ä»–æ–¹å¼å®ç°å®æ—¶æ›´æ–°
                    
                    train_btn.click(
                        self.start_training,
                        inputs=[selected_groups, selected_models],
                        outputs=[training_status]
                    )
                
                # è®­ç»ƒç»“æœæ ‡ç­¾é¡µ
                with gr.TabItem("ğŸ“ˆ è®­ç»ƒç»“æœ"):
                    gr.Markdown("## è®­ç»ƒç»“æœåˆ†æ")
                    
                    with gr.Row():
                        results_btn = gr.Button("åŠ è½½è®­ç»ƒç»“æœ", variant="secondary")
                        plot_group = gr.Dropdown(
                            choices=["group_1", "group_2", "group_3", "group_4", "group_5"],
                            label="é€‰æ‹©ç»„æŸ¥çœ‹å›¾è¡¨",
                            value="group_1"
                        )
                    
                    results_text = gr.Textbox(label="è®­ç»ƒç»“æœæ‘˜è¦", lines=15)
                    training_plot = gr.Plot(label="è®­ç»ƒæ›²çº¿")
                    
                    results_btn.click(
                        self.load_training_results,
                        outputs=[results_text]
                    )
                    
                    plot_group.change(
                        self.create_training_plots,
                        inputs=[plot_group],
                        outputs=[training_plot]
                    )
                
                # æ¨¡å‹é¢„æµ‹æ ‡ç­¾é¡µ
                with gr.TabItem("ğŸ”® æ¨¡å‹é¢„æµ‹"):
                    gr.Markdown("## æ¨¡å‹é¢„æµ‹")
                    
                    with gr.Tabs():
                        # å•ä¸ªé¢„æµ‹
                        with gr.TabItem("å•ä¸ªé¢„æµ‹"):
                            with gr.Row():
                                with gr.Column():
                                    input_values = gr.Textbox(
                                        label=f"è¾“å…¥å€¼ (é€—å·åˆ†éš”ï¼Œ{self.config.INPUT_DIM}ä¸ªå€¼)",
                                        placeholder="1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0"
                                    )
                                    
                                    pred_group = gr.Dropdown(
                                        choices=["group_1", "group_2", "group_3", "group_4", "group_5"],
                                        label="é€‰æ‹©æ•°æ®ç»„",
                                        value="group_1"
                                    )
                                    
                                    pred_model = gr.Dropdown(
                                        choices=["mlp", "resnet", "transformer"],
                                        label="é€‰æ‹©æ¨¡å‹",
                                        value="mlp"
                                    )
                                
                                with gr.Column():
                                    predict_btn = gr.Button("é¢„æµ‹", variant="primary")
                                    prediction_result = gr.Textbox(label="é¢„æµ‹ç»“æœ", lines=10)
                            
                            predict_btn.click(
                                self.predict_single,
                                inputs=[input_values, pred_group, pred_model],
                                outputs=[prediction_result]
                            )
                        
                        # æ‰¹é‡é¢„æµ‹
                        with gr.TabItem("æ‰¹é‡é¢„æµ‹"):
                            with gr.Row():
                                with gr.Column():
                                    batch_file = gr.File(label="ä¸Šä¼ CSVæ–‡ä»¶", file_types=[".csv"])
                                    
                                    batch_group = gr.Dropdown(
                                        choices=["group_1", "group_2", "group_3", "group_4", "group_5"],
                                        label="é€‰æ‹©æ•°æ®ç»„",
                                        value="group_1"
                                    )
                                    
                                    batch_models = gr.CheckboxGroup(
                                        choices=["mlp", "resnet", "transformer"],
                                        label="é€‰æ‹©æ¨¡å‹",
                                        value=["mlp"]
                                    )
                                
                                with gr.Column():
                                    batch_predict_btn = gr.Button("æ‰¹é‡é¢„æµ‹", variant="primary")
                                    batch_status = gr.Textbox(label="é¢„æµ‹çŠ¶æ€", lines=3)
                            
                            batch_results = gr.Dataframe(label="é¢„æµ‹ç»“æœ")
                            
                            batch_predict_btn.click(
                                self.batch_predict,
                                inputs=[batch_file, batch_group, batch_models],
                                outputs=[batch_status, batch_results]
                            )
        
        return app

def main():
    """ä¸»å‡½æ•°"""
    print("åˆå§‹åŒ–Gradioåº”ç”¨...")
    
    app_instance = GradioApp()
    interface = app_instance.create_interface()
    
    print("å¯åŠ¨Gradioç•Œé¢...")
    interface.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        debug=True
    )

if __name__ == "__main__":
    main()